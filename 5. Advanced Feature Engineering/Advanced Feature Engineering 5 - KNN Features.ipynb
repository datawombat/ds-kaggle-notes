{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These KNN features were key in various competitions. \n",
    "- A parallel version of KNN because it's heavy to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# np.random.seed(123)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure size\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 4\n",
    "plt.rc('figure.subplot', wspace=.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse \n",
    "\n",
    "train_path = 'data/X.npz'\n",
    "train_labels = 'data/Y.npy'\n",
    "\n",
    "test_path = 'data/X_test.npz'\n",
    "test_labels = 'data/Y_test.npy'\n",
    "\n",
    "# Train data\n",
    "X = scipy.sparse.load_npz(train_path)\n",
    "Y = np.load(train_labels)\n",
    "\n",
    "# Test data\n",
    "X_test = scipy.sparse.load_npz(test_path)\n",
    "Y_test = np.load(test_labels)\n",
    "\n",
    "# Out-of-fold features we loaded above were generated with n_splits=4 and skf seed 123\n",
    "# So it is better to use seed 123 for generating KNN features as well \n",
    "skf_seed = 123\n",
    "n_splits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NearestNeighborsFeats(BaseEstimator, ClassifierMixin):\n",
    "    '''\n",
    "        This class should implement KNN features extraction \n",
    "    '''\n",
    "    def __init__(self, n_jobs, k_list, metric, n_classes=None, n_neighbors=None, eps=1e-6):\n",
    "        self.n_jobs = n_jobs\n",
    "        self.k_list = k_list\n",
    "        self.metric = metric\n",
    "        \n",
    "        if n_neighbors is None:\n",
    "            self.n_neighbors = max(k_list) \n",
    "        else:\n",
    "            self.n_neighbors = n_neighbors\n",
    "            \n",
    "        self.eps = eps        \n",
    "        self.n_classes_ = n_classes\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "            Set's up the train set and self.NN object\n",
    "        '''\n",
    "        # Create a NearestNeighbors (NN) object. We will use it in `predict` function \n",
    "        self.NN = NearestNeighbors(n_neighbors=max(self.k_list), \n",
    "                                      metric=self.metric, \n",
    "                                      n_jobs=1, \n",
    "                                      algorithm='brute' if self.metric=='cosine' else 'auto')\n",
    "        self.NN.fit(X)\n",
    "       \n",
    "        # Store labels \n",
    "        self.y_train = y\n",
    "        \n",
    "        # Save how many classes we have\n",
    "        self.n_classes = np.unique(y).shape[0] if self.n_classes_ is None else self.n_classes_\n",
    "        \n",
    "        \n",
    "    def predict(self, X):       \n",
    "        '''\n",
    "            Produces KNN features for every object of a dataset X\n",
    "        '''\n",
    "        if self.n_jobs == 1:\n",
    "            test_feats = []\n",
    "            for i in range(X.shape[0]):\n",
    "                test_feats.append(self.get_features_for_one(X[i:i+1]))\n",
    "        else:\n",
    "            '''\n",
    "                 *Make it parallel*\n",
    "                     Number of threads should be controlled by `self.n_jobs`  \n",
    "                     \n",
    "                     \n",
    "                     You can use whatever you want to do it\n",
    "                     For Python 3 the simplest option would be to use \n",
    "                     `multiprocessing.Pool` (but don't use `multiprocessing.dummy.Pool` here)\n",
    "                     You may try use `joblib` but you will most likely encounter an error, \n",
    "                     that you will need to google up (and eventually it will work slowly)\n",
    "                     \n",
    "                     For Python 2 I also suggest using `multiprocessing.Pool` \n",
    "                     You will need to use a hint from this blog \n",
    "                     http://qingkaikong.blogspot.ru/2016/12/python-parallel-method-in-class.html\n",
    "                     I could not get `joblib` working at all for this code \n",
    "                     (but in general `joblib` is very convenient)\n",
    "                     \n",
    "            '''\n",
    "            \n",
    "            # YOUR CODE GOES HERE\n",
    "            \n",
    "            test_feats =[]\n",
    "            \n",
    "            pool = Pool(processes = self.n_jobs) \n",
    "            for i in range(X.shape[0]):\n",
    "                test_feats.append(pool.apply_async(self.get_features_for_one, (X[i:i+1],)))\n",
    "          \n",
    "            test_feats = [res.get() for res in test_feats]\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "            #assert False, 'You need to implement it for n_jobs > 1'\n",
    "            \n",
    "            \n",
    "            \n",
    "        return np.vstack(test_feats)\n",
    "        \n",
    "        \n",
    "    def get_features_for_one(self, x):\n",
    "        '''\n",
    "            Computes KNN features for a single object `x`\n",
    "        '''\n",
    "\n",
    "        NN_output = self.NN.kneighbors(x)\n",
    "        \n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores indices of the neighbors\n",
    "        neighs = NN_output[1][0]\n",
    "        \n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores distances to corresponding neighbors\n",
    "        neighs_dist = NN_output[0][0] \n",
    "        \n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores labels of corresponding neighbors\n",
    "        neighs_y = self.y_train[neighs] \n",
    "        \n",
    "        ## ========================================== ##\n",
    "        ##              YOUR CODE BELOW\n",
    "        ## ========================================== ##\n",
    "        \n",
    "        # We will accumulate the computed features here\n",
    "        # Eventually it will be a list of lists or np.arrays\n",
    "        # and we will use np.hstack to concatenate those\n",
    "        return_list = [] \n",
    "        \n",
    "        \n",
    "        ''' \n",
    "            1. Fraction of objects of every class.\n",
    "               It is basically a KNNÐ¡lassifiers predictions.\n",
    "\n",
    "               Take a look at `np.bincount` function, it can be very helpful\n",
    "               Note that the values should sum up to one\n",
    "        '''\n",
    "        ##*** feature1= 29(n_class) * 3(length of k_list)\n",
    "        for k in self.k_list:                                         \n",
    "            # YOUR CODE GOES HERE\n",
    "            feats = np.bincount(neighs_y[:k],minlength=self.n_classes)\n",
    "            feats  = feats / feats.sum()\n",
    "            #print(feats)\n",
    "            assert len(feats) == self.n_classes\n",
    "            return_list += [feats]\n",
    "            \n",
    "        '''\n",
    "            2. Same label streak: the largest number N, \n",
    "               such that N nearest neighbors have the same label\n",
    "               \n",
    "               What can help you:  `np.where`\n",
    "        '''\n",
    "        # YOUR CODE GOES HERE\n",
    "         ##*** feature2= 1\n",
    "        \n",
    "        if (neighs_y != neighs_y[0]).astype(int).sum() > 0:\n",
    "            #print(np.where(np.cumsum((neighs_y != neighs_y[0]).astype(int)) == 1))\n",
    "            feats = np.where(np.cumsum((neighs_y != neighs_y[0]).astype(int)) == 1)[0][0]\n",
    "        else:\n",
    "            feats = len(neighs_y)\n",
    "        #print('feature2:', feats)\n",
    "        feats = [feats]\n",
    "        assert len(feats) == 1\n",
    "        return_list += [feats]\n",
    "        \n",
    "        '''\n",
    "            3. Minimum distance to objects of each class\n",
    "               Find the first instance of a class and take its distance as features.\n",
    "               \n",
    "               If there are no neighboring objects of some classes, \n",
    "               Then set distance to that class to be 999\n",
    "\n",
    "               `np.where` might be helpful\n",
    "        '''\n",
    "        ##*** feature3= 29\n",
    "        feats = []\n",
    "        for c in range(self.n_classes):\n",
    "            # YOUR CODE GOES HERE\n",
    "            \n",
    "            feat = neighs_dist[neighs_y == c][0] if (neighs_y == c).sum() > 0 else 999\n",
    "            feats.append(feat)\n",
    "        #print('feature3:', min(feats))\n",
    "        assert len(feats) == self.n_classes\n",
    "        return_list += [feats]\n",
    "        \n",
    "        '''\n",
    "            4. Minimum *normalized* distance to objects of each class\n",
    "               As 3. but we normalize (divide) the distances\n",
    "               by the distance to the closest neighbor.\n",
    "               \n",
    "               Do not forget to add self.eps to denominator\n",
    "        '''\n",
    "        ##*** feature4= 29\n",
    "        feats = []\n",
    "        for c in range(self.n_classes):\n",
    "            # YOUR CODE GOES HERE\n",
    "            feat = neighs_dist[neighs_y == c][0] if (neighs_y == c).sum() > 0 else 999\n",
    "            if feat!= 999:\n",
    "                feat = feat / (self.eps + neighs_dist[0])\n",
    "            feats.append(feat)\n",
    "       \n",
    "        assert len(feats) == self.n_classes\n",
    "        return_list += [feats]\n",
    "        \n",
    "        '''\n",
    "            5. \n",
    "               5.1 Distance to Kth neighbor\n",
    "                   Think of this as of quantiles of a distribution\n",
    "               5.2 Distance to Kth neighbor normalized by \n",
    "                   distance to the first neighbor\n",
    "               \n",
    "               feat_51, feat_52 are answers to 5.1. and 5.2.\n",
    "               should be scalars\n",
    "        '''\n",
    "        ##*** feature5= 2*3\n",
    "        for k in self.k_list:\n",
    "            \n",
    "            feat_51 = neighs_dist[k-1] # YOUR CODE GOES HERE\n",
    "            feat_52 = neighs_dist[k-1] / (neighs_dist[0] + self.eps) # YOUR CODE GOES HERE\n",
    "            \n",
    "            return_list += [[feat_51, feat_52]]\n",
    "        \n",
    "        '''\n",
    "            6. Mean distance to neighbors of each class for each K from `k_list` \n",
    "                   For each class select the neighbors of that class among K nearest neighbors \n",
    "                   and compute the average distance to those objects\n",
    "                   \n",
    "                   If there are no objects of a certain class among K neighbors, set mean distance to 999\n",
    "                   \n",
    "               You can use `np.bincount` with appropriate weights\n",
    "               Don't forget, that if you divide by something, \n",
    "               You need to add `self.eps` to denominator\n",
    "        '''\n",
    "        ##*** feature6= 29*3\n",
    "        for k in self.k_list:\n",
    "            \n",
    "            # YOUR CODE GOES IN HERE\n",
    "            numerator = np.zeros(self.n_classes)\n",
    "            denominator = np.full(self.n_classes, self.eps)\n",
    "            t = neighs_y[:k].max() + 1\n",
    "            numerator[:t] = np.bincount(neighs_y[:k], weights=neighs_dist[:k])\n",
    "            denominator[:t] = self.eps + np.bincount(neighs_y[:k])\n",
    "            feats = np.where(numerator>0, numerator/denominator, 999)\n",
    "            assert len(feats) == self.n_classes\n",
    "            return_list += [feats]\n",
    "        \n",
    "        \n",
    "        # merge\n",
    "        knn_feats = np.hstack(return_list)\n",
    "        #print('knn_feats shape:', knn_feats.shape)\n",
    "        assert knn_feats.shape == (239,) or knn_feats.shape == (239, 1)\n",
    "        return knn_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of processes must be at least 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1c85154331e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Get features for test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtest_knn_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNNF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# This should be zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-ee250551051f>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mtest_feats\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mtest_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features_for_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36mPool\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         return Pool(processes, initializer, initargs, maxtasksperchild,\n\u001b[0;32m--> 119\u001b[0;31m                     context=self.get_context())\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mRawValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypecode_or_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mprocesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprocesses\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of processes must be at least 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitializer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of processes must be at least 1"
     ]
    }
   ],
   "source": [
    "# a list of K in KNN, starts with one \n",
    "k_list = [3, 8, 32]\n",
    "\n",
    "# Load correct features\n",
    "true_knn_feats_first50 = np.load('data/knn_feats_test_first50.npy')\n",
    "\n",
    "# Create instance of our KNN feature extractor\n",
    "NNF = NearestNeighborsFeats(n_jobs=-1, k_list=k_list, metric='minkowski')\n",
    "\n",
    "# Fit on train set\n",
    "NNF.fit(X, Y)\n",
    "\n",
    "# Get features for test\n",
    "test_knn_feats = NNF.predict(X_test[:50])\n",
    "\n",
    "# This should be zero\n",
    "print (np.abs(test_knn_feats - true_knn_feats_first50).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features for test\n",
    "\n",
    "Features for the whole test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['minkowski', 'cosine']:\n",
    "    print (metric)\n",
    "    \n",
    "    # Create instance of our KNN feature extractor\n",
    "    NNF = NearestNeighborsFeats(n_jobs=4, k_list=k_list, metric=metric)\n",
    "    \n",
    "    # Fit on train set\n",
    "    NNF.fit(X, Y)\n",
    "\n",
    "    # Get features for test\n",
    "    test_knn_feats = NNF.predict(X_test)\n",
    "    \n",
    "    # Dump the features to disk\n",
    "    np.save('data/knn_feats_%s_test.npy' % metric , test_knn_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features for train\n",
    "\n",
    "Compute features for train, using out-of-fold strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf_seed = 123\n",
    "\n",
    "# Differently from other homework we will not implement OOF predictions ourselves\n",
    "# but use sklearn's `cross_val_predict`\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# We will use two metrics for KNN\n",
    "for metric in ['minkowski', 'cosine']:\n",
    "    print (metric)\n",
    "    \n",
    "    # Set up splitting scheme, use StratifiedKFold\n",
    "    # use skf_seed and n_splits defined above with shuffle=True\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=skf_seed, shuffle=True)\n",
    "    \n",
    "    # Create instance of our KNN feature extractor\n",
    "    # n_jobs can be larger than the number of cores\n",
    "    NNF = NearestNeighborsFeats(n_jobs=-1, k_list=k_list, metric=metric)\n",
    "    \n",
    "    # Get KNN features using OOF use cross_val_predict with right parameters\n",
    "    preds = cross_val_predict(NNF, X, Y, cv=skf)   \n",
    "    \n",
    "    # Save the features\n",
    "    np.save('data/knn_feats_%s_train.npy' % metric, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for metric in ['minkowski', 'cosine']:\n",
    "    knn_feats_train = np.load('data/knn_feats_%s_train.npy' % metric)\n",
    "    knn_feats_test = np.load('data/knn_feats_%s_test.npy' % metric)\n",
    "    \n",
    "    s += knn_feats_train.mean() + knn_feats_test.mean()\n",
    "    \n",
    "answer = np.floor(s)\n",
    "print (answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
