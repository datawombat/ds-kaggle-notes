{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# np.random.seed(123)\n",
    "sns.set_style(\"whitegrid\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigger font\n",
    "# sns.set_context(\"poster\")\n",
    "# sns.set(style=\"white\", font_scale=2)\n",
    "# Gray style\n",
    "sns.set(font_scale=2)\n",
    "plt.style.use('fivethirtyeight')\n",
    "# Figure size\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 4\n",
    "plt.rc('figure.subplot', wspace=.33)\n",
    "# Slides\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1024,\n",
    "        'height': 768,\n",
    "        'scroll': True,\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When using a polynomial model, a too high degree = overfitting\n",
    "- If parameteres are too large e.g. [130, -525.8, 102.6], the model is overfitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Strategies\n",
    "\n",
    "There are 4 recommended ways to avoid overfitting.\n",
    "\n",
    "Having a dataset with $N$ samples (this would be the TRAIN set in Kaggle competitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1, 1], \n",
    "              [2, 2], \n",
    "              [3, 3], \n",
    "              [4, 4], \n",
    "              [5, 5], \n",
    "              [6, 6]])\n",
    "y_train = np.array([1, 1, 1, 1, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Hold-out Validation\n",
    "\n",
    "- This shuffles and splits the data into TRAIN and TEST.\n",
    "- In Deep Learning, this is what's preferred.\n",
    "\n",
    "![](overfitting1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 2 3 5] TEST: [4 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "rs = ShuffleSplit(n_splits=1, test_size=.20)\n",
    "\n",
    "for a_index, e_index in rs.split(X_train):\n",
    "    print(\"TRAIN:\", a_index, \"TEST:\", e_index)\n",
    "    X_a, X_e = X_train[a_index], X_train[e_index]\n",
    "    y_a, y_e = y_train[a_index], y_train[e_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. K-fold / K-fold Cross Validation\n",
    "\n",
    "- This can be seen as a repeated hold-out and we use every part of TRAIN as VALIDATION in each of the K iterations.\n",
    "- Then, we need to average scores over these K folds.\n",
    "\n",
    "![](images/kfold_iterations.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [2 3 4 5] TEST: [0 1]\n",
      "TRAIN: [0 1 4 5] TEST: [2 3]\n",
      "TRAIN: [0 1 2 3] TEST: [4 5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "for a_index, e_index in kf.split(X_train):\n",
    "    print(\"TRAIN:\", a_index, \"TEST:\", e_index)\n",
    "    X_a, X_e = X_train[a_index], X_train[e_index]\n",
    "    y_a, y_e = y_train[a_index], y_train[e_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Leave-one-out Validation\n",
    "\n",
    "- Here the number of folds is the length of TRAIN, which is $N$.\n",
    "- It does the same as K fold but it splits the data into $N - 1$ TRAIN samples and $1$ sample is the TEST set.\n",
    "- It can be super slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [1 2 3 4 5] TEST: [0]\n",
      "TRAIN: [0 2 3 4 5] TEST: [1]\n",
      "TRAIN: [0 1 3 4 5] TEST: [2]\n",
      "TRAIN: [0 1 2 4 5] TEST: [3]\n",
      "TRAIN: [0 1 2 3 5] TEST: [4]\n",
      "TRAIN: [0 1 2 3 4] TEST: [5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "for a_index, e_index in loo.split(X_train):\n",
    "    print(\"TRAIN:\", a_index, \"TEST:\", e_index)\n",
    "    X_a, X_e = X_train[a_index], X_train[e_index]\n",
    "    y_a, y_e = y_train[a_index], y_train[e_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Stratified K-fold\n",
    "\n",
    "- This applies stratification, which returns stratified folds. The folds are made by preserving the percentage of samples for each class.\n",
    "- Useful for **small datasets, unbalanced datasets, multiclass classification**.\n",
    "\n",
    "![](images/stratification.jpg)\n",
    "\n",
    "The first folds would come from the simple k-fold algorithm, and the other would use stratified folds. Those gray rows have scores a model would get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2\n",
       "0  1  1  1\n",
       "1  2  2  1\n",
       "2  3  3  1\n",
       "3  4  4  1\n",
       "4  5  5  2\n",
       "5  6  6  2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(np.concatenate((X_train, y_train[:, np.newaxis]),1))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [2 3 5] TEST: [0 1 4]\n",
      "TRAIN: [0 1 3 4] TEST: [2 5]\n",
      "TRAIN: [0 1 2 4 5] TEST: [3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "for a_index, e_index in skf.split(X_train, y_train):\n",
    "    print(\"TRAIN:\", a_index, \"TEST:\", e_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e. Predefined Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 4 5] TEST: [1 2 3]\n",
      "TRAIN: [0 1 2 3] TEST: [4 5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "# from sklearn.cross_validation import PredefinedSplit ## DEPRECATED\n",
    "\n",
    "ps = PredefinedSplit(test_fold=([-1,0,0,0,1,1]))  ## only parameter = test_fold, 1 = test data, -1 = not in test\n",
    "\n",
    "for a_index, e_index in ps.split():\n",
    "    print(\"TRAIN:\", a_index, \"TEST:\", e_index)\n",
    "    X_a, X_e = X_train[a_index], X_train[e_index]\n",
    "    y_a, y_e = y_train[a_index], y_train[e_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation strategies that consider a correct splitting\n",
    "\n",
    "After doing feature engineering, we should get a training and a validation set, because we also do the splitting part there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1, 1], \n",
    "              [2, 2], \n",
    "              [3, 3], \n",
    "              [4, 4], \n",
    "              [5, 5], \n",
    "              [6, 6]])\n",
    "y_train = np.array([1, 1, 1, 1, 2, 2])\n",
    "\n",
    "X_val = np.array([[7, 7], \n",
    "              [8, 8], \n",
    "              [9, 9], \n",
    "              [10, 10]])\n",
    "y_val = np.array([2, 2, 3, 3])\n",
    "\n",
    "# This is for training the final models\n",
    "X = np.concatenate((X_train, X_val))\n",
    "y = np.append(y_train, y_val)\n",
    "\n",
    "# This is for testing the final model\n",
    "X_test_leaderboard = np.array([[11, 11], \n",
    "                              [12, 12], \n",
    "                              [13, 13], \n",
    "                              [14, 14]])\n",
    "y_test_leaderboard = np.array([3, 3, 4, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This only serves as input for GridSearch.\n",
    "\n",
    "It simply separates train and test for the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind = np.zeros(X.shape[0])\n",
    "for i in range(0, len(X_train)):\n",
    "    train_ind[i] = -1\n",
    "ps = PredefinedSplit(test_fold=(train_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 6 candidates, totalling 6 fits\n",
      "[CV] alpha=0.1, normalize=True .......................................\n",
      "[CV] alpha=0.1, normalize=False ......................................\n",
      "[CV] alpha=0.2, normalize=True .......................................\n",
      "[CV] alpha=0.2, normalize=False ......................................\n",
      "[CV]  alpha=0.1, normalize=True, score=-0.8502469500376576, total=   0.0s\n",
      "[CV]  alpha=0.1, normalize=False, score=-0.37552080237434643, total=   0.0s\n",
      "[CV] alpha=0.3, normalize=True .......................................\n",
      "[CV]  alpha=0.2, normalize=False, score=-0.5064034403955454, total=   0.0s\n",
      "[CV]  alpha=0.2, normalize=True, score=-1.2692955176439846, total=   0.0s\n",
      "[CV] alpha=0.3, normalize=False ......................................\n",
      "[CV]  alpha=0.3, normalize=True, score=-1.2692955176439846, total=   0.0s\n",
      "[CV]  alpha=0.3, normalize=False, score=-0.6584734630851129, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "params = {'alpha':[0.1,0.2,0.3],\n",
    "         'normalize':[True, False]}\n",
    "\n",
    "model = Lasso()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "score = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "best_model = GridSearchCV(model, params, verbose=3, n_jobs=-1, cv=ps, scoring=score)\n",
    "best_model.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.14545455, 2.37575758, 2.60606061, 2.83636364])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val = best_model.predict(X_val)\n",
    "pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE 0.264361\n",
      "Val RMSE 0.293392\n"
     ]
    }
   ],
   "source": [
    "print('Train RMSE %f' % rmse(y_train, best_model.predict(X_train)))\n",
    "print('Val RMSE %f' % rmse(y_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to GridSearchCV, not all parameter values are tried out, but rather a sample from them. I don't think this is useful though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation problems\n",
    "\n",
    "- Too little data.\n",
    "- Diverse or inconsistent data. Very similar samples with different targets.\n",
    "    - In a time series, for example, a month can have more holydays than previous ones, so using previous months would be unfavorable.\n",
    "\n",
    "#### How to do more thorough validation\n",
    "\n",
    "- Increase K\n",
    "- Tune the model on one set of k-fold splits and evaluate it on the other."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
