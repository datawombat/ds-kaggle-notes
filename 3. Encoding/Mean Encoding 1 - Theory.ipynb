{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "# Bigger font\n",
    "# sns.set_context(\"poster\")\n",
    "sns.set_context(\"talk\")\n",
    "# Figure size\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 4\n",
    "# np.random.seed(123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Encoding has many names:\n",
    "- Likelihood Encoding\n",
    "- Target Encoding\n",
    "\n",
    "It mostly consists on encoding each level of the categorical variable with its corresponding target mean.\n",
    "\n",
    "## Why mean encoding?\n",
    "\n",
    "![](images/label_encoding.png)\n",
    "Because \"Feature\" is a categorical feature, Label encoding would be what comes to mind first.\n",
    "\n",
    "But mean encoding is supposedly better. It is about encoding every city with the corresponding mean target, so feature_mean is created 0.4 = 2/5 (this comes from the target column).\n",
    "\n",
    "- Label encoding gives random order. No correlation with the target.\n",
    "- Mean encoding makes classes look more separable.\n",
    "\n",
    "Using Gradient Boosting Trees.\n",
    "- We can reach better loss with shorter(less deep) trees."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to use mean encoding?\n",
    "- When there are categorical variables with a lot of levels.\n",
    "- The plots below indicate 3 models with depth 7, 9 and 11\n",
    "    - The AUC keeps increasing but we don't overfit (this would happen when the model's AUC gets to 1 on the TRAIN and on the VALIDATION set it just fails by decreasing). \n",
    "    - **If it doesn't overfit**, the trees need a huge number of splits to extract information from some variables. Some features can have 1600 split points. \n",
    "\n",
    "![](images/train_test_mean_encoding.png)\n",
    "## Ways to calculate mean encoding?\n",
    "\n",
    "For example, if we have binary levels. Goods = number of ones in a group, Bads = number of zeros\n",
    "\n",
    "- Likelihood = Goods/(Goods + Bads) = mean(target)\n",
    "- Weight of evidence = ln(Goods/Bads) * 100\n",
    "- Count = Goods = sum(target)\n",
    "- Diff = Goods - Bads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to do mean encoding?\n",
    "\n",
    "1. Separate the data into train and validation.\n",
    "2. Compute the mean of the target for certain column. For example, here we have 'Points' as the target and we can group by 'Team' because it is categorical and it is assumed to have many levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Year</th>\n",
       "      <th>Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Riders</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Riders</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Devils</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Devils</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kings</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Team  Rank  Year  Points\n",
       "0  Riders     1  2014     876\n",
       "1  Riders     2  2015     789\n",
       "2  Devils     2  2014     863\n",
       "3  Devils     3  2015     673\n",
       "4   Kings     3  2014     741"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\n",
    "         'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\n",
    "         'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
    "         'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
    "         'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}\n",
    "data = pd.DataFrame(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_new, val_new = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rgap/.virtualenvs/rgap-lectures/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/rgap/.virtualenvs/rgap-lectures/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Year</th>\n",
       "      <th>Points</th>\n",
       "      <th>Team_mean_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Riders</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>876</td>\n",
       "      <td>762.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Devils</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>673</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Devils</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>863</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kings</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>812</td>\n",
       "      <td>812.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kings</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>788</td>\n",
       "      <td>761.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Team  Rank  Year  Points  Team_mean_target\n",
       "0  Riders     1  2014     876        762.250000\n",
       "3  Devils     3  2015     673        768.000000\n",
       "2  Devils     2  2014     863        768.000000\n",
       "5   kings     4  2015     812        812.000000\n",
       "7   Kings     1  2017     788        761.666667"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = 'Team'\n",
    "means = data.groupby(col)['Points'].mean()\n",
    "train_new[col + '_mean_target'] = train_new[col].map(means)\n",
    "val_new[col + '_mean_target'] = val_new[col].map(means)\n",
    "train_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After repeating that process for every categorical column, we can use xgboost. In this case there was only one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:563.604\teval-rmse:557.102\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 200 rounds.\n",
      "[30]\ttrain-rmse:1.60038\teval-rmse:68.1456\n",
      "[60]\ttrain-rmse:0.012226\teval-rmse:68.3904\n",
      "[90]\ttrain-rmse:0.001006\teval-rmse:68.3922\n",
      "[120]\ttrain-rmse:0.001006\teval-rmse:68.3922\n",
      "[150]\ttrain-rmse:0.001006\teval-rmse:68.3922\n",
      "[180]\ttrain-rmse:0.001006\teval-rmse:68.3922\n",
      "[210]\ttrain-rmse:0.001006\teval-rmse:68.3922\n",
      "Stopping. Best iteration:\n",
      "[19]\ttrain-rmse:9.70156\teval-rmse:66.8223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(train_new.iloc[:,(train_new.columns != 'Team') & (train_new.columns != 'Points')], label=train_new['Points'].values)\n",
    "dvalid = xgb.DMatrix(val_new.iloc[:,(val_new.columns != 'Team') & (train_new.columns != 'Points')], label=val_new['Points'].values)\n",
    "\n",
    "evallist = [(dtrain, 'train'),(dvalid, 'eval')]\n",
    "evals_result3 = {}\n",
    "\n",
    "xgb_par = {'max_depth':100,\n",
    "         'eval_metric':'rmse'}\n",
    "model = xgb.train(xgb_par, dtrain, 3000, evals=evallist,verbose_eval=30,evals_result=evals_result3,early_stopping_rounds=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.39220282238342\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(xgb.DMatrix(val_new.loc[:,(val_new.columns != 'Team') & (train_new.columns != 'Points')]))\n",
    "from sklearn.metrics import mean_squared_error \n",
    "rmse = np.sqrt(mean_squared_error(preds,val_new.iloc[:, val_new.columns == 'Points'].values))\n",
    "print(rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There is overfitting. Only the train data was used to estimate mean encodings.\n",
    "\n",
    "If we had done mean encoding before the train-validation split, the model wouldn't overfit.\n",
    "\n",
    "Anyway, it essentially overfits because the mean-encoded feature becomes a good descriptor for the target. This is apparently known as **leakage from the target variable**.\n",
    "\n",
    "We need to do some regularization first.\n",
    "\n",
    "## Ways to do regularization\n",
    "\n",
    "#### 1. CV loop inside train data (CV Loop and LOO regularization)\n",
    "\n",
    "This consists on doing mean encoding for a fold by not using the data from that fold but from the rest of folds. 4-5 folds are enough.\n",
    "\n",
    "**This may result in some NaNs. In that case, they filled with the global mean.**\n",
    "\n",
    "This is an example using Leave one out.\n",
    "\n",
    "![](images/leave_one_out_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Smoothing based on the size of the category\n",
    "\n",
    "- If the category is very common, then we can trust the mean encoding.\n",
    "- If the category is very rare, we can't.\n",
    "\n",
    "With this method we use \"alpha\" as a regularizer.\n",
    "\n",
    "$$\\frac{mean(target)*nrows + globalmean*alpha}{nrows + alpha}$$\n",
    "\n",
    "When alpha is very large, everything turns into the global mean, and it punishes rare categories. Smoothing can be combined with CV loop regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Adding random noise\n",
    "\n",
    "Adding noise degrades the quality of encoding in the train data.\n",
    "\n",
    "It is hard to make this method work. It is usually used together with LOO regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Sorting and calculating expanding mean on some permutation of the data\n",
    "\n",
    "It is about using only rows from 0 to n-1 to calculate the encoding for row n.\n",
    "\n",
    "- Least amount of leakage\n",
    "- No hyper parameters\n",
    "- But it produces irregular encoding quality\n",
    "- It is implemented in \"Catboost gradient boosting library\", which is used in datasets with categorical features.\n",
    "\n",
    "These methods are better explained in this video  https://www.coursera.org/learn/competitive-data-science/lecture/LGYQ2/regularization\n",
    "\n",
    "It is better to try them out by using them with real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real example where to use mean encoding\n",
    "\n",
    "**This is where it is a good moment to start finding a pipeline and model for the competition.**\n",
    "\n",
    "https://www.kaggle.com/c/competitive-data-science-predict-future-sales\n",
    "\n",
    "Task: **Forecast the total amount of products of each type that will be sold in every shop for the test set.**\n",
    "\n",
    "Something important to take into account in this dataset is this field:\n",
    "\n",
    "date_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  date_block_num  shop_id  item_id  item_price  item_cnt_day\n",
       "0 2013-01-02               0       59    22154       999.0           1.0\n",
       "1 2013-01-03               0       25     2552       899.0           1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv('data/sales_train.csv.gz')\n",
    "sales['date'] = pd.to_datetime(sales['date'], format='%d.%m.%Y')\n",
    "sales.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that the test set is only data from the month November 2015, and it contains products and their shops and we have to predict the amount sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  shop_id  item_id\n",
       "0   0        5     5037\n",
       "1   1        5     5320"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/test.csv.gz')\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What categorical or ordinal features are there?\n",
    "\n",
    "- item_id\n",
    "- shop_id\n",
    "\n",
    "Even 'date_block_num' but I don't think is it good to encode that one in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
